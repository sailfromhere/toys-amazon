---
title: "Toys Amazon Project"
author: "Kevin Yu"
date: "10/21/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, echo=FALSE}

library(tidyverse)
library(lubridate)

```

## Appendix I
## Metadata

## Appendix II
## Sample Code

This section includes samples of the code I wrote to clean the original dataset. I mainly used packages within `tidyverse`, for example, `readr` to import and export data, `dplyr` and `tidyr` to reshape the dataset into clean format, and `stringr` to manipulate string variables using regular expression. I also used the `lubridate` package to parse dates. Functions and loops were also used to write more efficient code.

### import data

I used the `readr` package to read the data and specify column type.

```{r import data, eval=FALSE}

Toys_Amazon <- read_csv("Toys_Amazon.csv", 
                        # specify data type as numeric to avoid parsing error
                        col_types = cols(number_of_reviews = col_number()))

```

### split data

I used the `dplyr` package to split the data into 7 dataframes.

```{r split data, eval=FALSE}

product <- Toys_Amazon %>%
  select(uniq_id, product_name, manufacturer, price,
         number_available_in_stock, number_of_reviews,
         number_of_answered_questions, average_review_rating,
         description, product_information, product_description)

cat <- Toys_Amazon %>%
  select(uniq_id, amazon_category_and_sub_category)

also_bought <- Toys_Amazon %>%
  select(uniq_id, customers_who_bought_this_item_also_bought)

bought_after <- Toys_Amazon %>%
  select(uniq_id, items_customers_buy_after_viewing_this_item)

qa <- Toys_Amazon %>%
  select(uniq_id, customer_questions_and_answers)

reviews <- Toys_Amazon %>%
  select(uniq_id, customer_reviews)

sellers <- Toys_Amazon %>%
  select(uniq_id, sellers)

```

### clean the product dataframe with tidyverse

Multiple techniques were used to clean the `product` dataframe. To demonstrate, I used the `mutate()` function in the `dplyr` package to transform the `price` variable into numbers:

```{r price, eval=FALSE}

df1 <- product %>%
  # parse price as numeric
  mutate(price = parse_number(price))

```

or the `separate()` function in the `tidyr` package to separate number available into availability and condition:

```{r availability, eval=FALSE}

df2 <- df1 %>%
  # separate into availability and condition
  separate(number_available_in_stock, 
           into = c("number_available", "condition")) %>%
  # parse availability as numeric
  mutate(number_available = parse_number(number_available))

```

or regular expression to remove the " out of 5 stars" in the `average_review_rating` variable and keep only the rating numbers:

```{r rating, eval=FALSE}

df3 <- df2 %>%
  mutate(
    average_review_rating = 
      # parse as number
      parse_number(
        # extract the ratings
        str_extract(
          average_review_rating, 
          # use regular expression to 
          # look for the ratings
          "[:digit:]\\.[:digit:](?=[:space:])"
        )
      )
  )

```

I also investigated the similarity between the `description` and `product_description` variables with the `ifelse()` function in the base R package and the `filter()` function in the `dplyr` package, and discovered that they are identical:

```{r description, eval=FALSE}

tmp <- df3

# create variable that returns 1 
# when description is different from 
# product_description
tmp$isdiff <- ifelse(tmp$description == 
                       tmp$product_description,
                     0, 1)

# output the observations that are different
tmp <- tmp %>%
  select(description, product_description) %>%
  filter(tmp$isdiff == 1)

```

### function to clean amazon url

Variables `customers_who_bought_this_item_also_bought` and `items_customers_buy_after_viewing_this_item` are very similar: they are both a collection of amazon urls associated with each observation. To reduce the redundancy of my code, I wrote a function to clean these urls and applied it to the two variables.

```{r function, eval=FALSE}

clean_amzn_url <- function(data, col, into, n) {
  
  tmp <- data
  
  # clean urls into product names
  tmp[[col]] <-
    tmp[[col]] %>%
    # remove head of urls
    str_remove_all("http://www.amazon.co.uk/") %>%
    # replace dashes with spaces
    str_replace_all("\\-", " ") %>%
    # remove tail of urls
    str_remove_all("(?<=\\/dp\\/)[:alnum:]*(?=[:space:]\\|[:space:])") %>%
    # remove tail of the last url in a cell
    str_remove("(?<=\\/dp\\/)[:alnum:]*(?![:blank:])") %>%
    # remove the remnant of urls
    str_remove_all("\\/dp\\/")
  
  tmp <- tmp %>%
    # separate each product into a new column
    separate(col,
             into = c(paste0(into, 1:n)),
             sep = " \\| ") %>%
    # gather new columns into clean format
    pivot_longer(c(paste0(into, 1:n)), 
                 names_to = paste0(into, "_key"), 
                 values_to = paste0(into, "_product")) %>%
    # drop na rows
    drop_na()

  return(tmp)
  
}

# use the function to clean also_bought dataframe
also_bought <- also_bought %>%
  clean_amzn_url(col = "customers_who_bought_this_item_also_bought",
                 into = "also_bought",
                 # max of 12 also_bought products
                 n = 12)

# use the function to clean bought_after_viewing dataframe
bought_after <- bought_after %>%
  clean_amzn_url(col = "items_customers_buy_after_viewing_this_item",
                 into = "bought_after_viewing",
                 # max of 4 bought_after_viewing products
                 n = 4)

```

### use pivot_longer() to gather data

I used the `pivot_longer()` function (formerly the `gather()` function) in the `tidyr` package a lot to gather the data into clean format. To demonstrate, below is my code, which includes the use of `pivot_longer()` to clean the `qa` dataframe:

```{r pivot, eval=F}

df1 <- qa %>%
  # separate into 10 qa sets
  separate(customer_questions_and_answers,
           into = c(paste0("question_set", 1:10)),
           sep = " \\| ")

df2 <- df1 %>%
  # gather qa sets into clean format
  pivot_longer(c(paste0("question_set", 1:10)),
               names_to = "question_sets",
               values_to = "question_answer") %>%
  # drop na columns
  drop_na()

df3 <- df2 %>%
  # separate each qa set into question & answer
  separate("question_answer",
           into = c("question", "answer"),
           sep = " // ")

```

### use loops

Loops are also used in the process of data cleaning. One example is then I loop over the `reviews` dataframe to replace empty `reviewer_credential` variable cells with `NA`s:

```{r loop, eval=FALSE}

for (i in 1:nrow(df1)) {
  df1[i, "reviewer_credential"] <-
    ifelse(df1[i, "reviewer_credential"] != "",
           df1[i, "reviewer_credential"],
           NA)
}

```

A combination of the above functions and techniques was also used to clean the `cat`, `also_bought`, `bought_after`, and `sellers` dataframes.








